{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa37c6e9",
   "metadata": {},
   "source": [
    "## Importing Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d557c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8bb6a",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d2959b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam.csv\", encoding='latin1')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac1dc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1   ham                      Ok lar... Joking wif u oni...     0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3   ham  U dun say so early hor... U c already then say...     0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spam'] = df['type'].map({\"spam\":1, \"ham\":0}).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d374924",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556a776a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]#before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d225f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6f4ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]#after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62930e",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f18901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]#before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debbafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "porter = SnowballStemmer(\"english\", ignore_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75fcc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda x: [porter.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01dbd89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok', 'lar...', 'joke', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]#after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458674ea",
   "metadata": {},
   "source": [
    "## Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efedbd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahhh.',\n",
       " 'work.',\n",
       " 'i',\n",
       " 'vagu',\n",
       " 'rememb',\n",
       " 'that!',\n",
       " 'what',\n",
       " 'doe',\n",
       " 'it',\n",
       " 'feel',\n",
       " 'like?',\n",
       " 'lol']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][29]#before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56c974da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9d1dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda x : [lemmatizer.lemmatize(word, pos=\"a\") for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8806fb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahhh.',\n",
       " 'work.',\n",
       " 'i',\n",
       " 'vagu',\n",
       " 'rememb',\n",
       " 'that!',\n",
       " 'what',\n",
       " 'doe',\n",
       " 'it',\n",
       " 'feel',\n",
       " 'like?',\n",
       " 'lol']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][29]#after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d1b71",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec1d98be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello!',\n",
       " 'how',\n",
       " 'you',\n",
       " 'and',\n",
       " 'how',\n",
       " 'did',\n",
       " 'saturday',\n",
       " 'go?',\n",
       " 'i',\n",
       " 'was',\n",
       " 'just',\n",
       " 'text',\n",
       " 'to',\n",
       " 'see',\n",
       " 'if',\n",
       " \"you'd\",\n",
       " 'decid',\n",
       " 'to',\n",
       " 'do',\n",
       " 'anyth',\n",
       " 'tomo.',\n",
       " 'not',\n",
       " 'that',\n",
       " \"i'm\",\n",
       " 'tri',\n",
       " 'to',\n",
       " 'invit',\n",
       " 'myself',\n",
       " 'or',\n",
       " 'anything!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][39]#before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26dca502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183ff9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello! saturday go? text see decid anyth tomo. i'm tri invit anything!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda x : [word for word in x if not word in stop_words]).apply(' '.join)\n",
    "df['text'][39]#after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84105847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point, crazy.. avail onli bugi n gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joke wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor... u c alreadi say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goe usf, live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey darl 3 week word back! i'd like fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even brother like speak me. treat like aid pat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>per request mell mell (oru minnaminungint nuru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner!! valu network custom select receivea â...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>mobil 11 month more? u r entitl updat late col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  spam\n",
       "0   ham  go jurong point, crazy.. avail onli bugi n gre...     0\n",
       "1   ham                        ok lar... joke wif u oni...     0\n",
       "2  spam  free entri 2 wkli comp win fa cup final tkts 2...     1\n",
       "3   ham          u dun say earli hor... u c alreadi say...     0\n",
       "4   ham              nah think goe usf, live around though     0\n",
       "5  spam  freemsg hey darl 3 week word back! i'd like fu...     1\n",
       "6   ham  even brother like speak me. treat like aid pat...     0\n",
       "7   ham  per request mell mell (oru minnaminungint nuru...     0\n",
       "8  spam  winner!! valu network custom select receivea â...     1\n",
       "9  spam  mobil 11 month more? u r entitl updat late col...     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d056cc1",
   "metadata": {},
   "source": [
    "## Transforming Text Data into TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e951ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a0141ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "y = df.spam.values\n",
    "x = tfidf.fit_transform(df[\"text\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56a8809",
   "metadata": {},
   "source": [
    "## Classification using Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3256b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d521cdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 87.5\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "acc_model = accuracy_score(y_pred, y_test)*100\n",
    "print(\"accuracy :\", acc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22e851",
   "metadata": {},
   "source": [
    "## Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "437c5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "490e7564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 87.5\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "acc_model = accuracy_score(y_pred, y_test)*100\n",
    "print(\"accuracy :\", acc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be328354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
